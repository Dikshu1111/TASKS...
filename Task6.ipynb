{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0a066e-99b0-4eeb-8c2e-ed78f4bf8560",
   "metadata": {},
   "source": [
    "TASK 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff50a8-63d9-4dc4-bb79-96426f0cc5d4",
   "metadata": {},
   "source": [
    "1) Scrape all product names and prices from the first two pages of \"Books to Scrape\" (http://books.toscrape.com/). Handle simple pagination and structure the output as a list of dictionaries with 'title' and 'price'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3048ff-4a64-45f0-8eda-c3f368ad5652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'A Light in the Attic', 'price': 'Â£51.77'}, {'title': 'Tipping the Velvet', 'price': 'Â£53.74'}, {'title': 'Soumission', 'price': 'Â£50.10'}, {'title': 'Sharp Objects', 'price': 'Â£47.82'}, {'title': 'Sapiens: A Brief History of Humankind', 'price': 'Â£54.23'}, {'title': 'The Requiem Red', 'price': 'Â£22.65'}, {'title': 'The Dirty Little Secrets of Getting Your Dream Job', 'price': 'Â£33.34'}, {'title': 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 'price': 'Â£17.93'}, {'title': 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 'price': 'Â£22.60'}, {'title': 'The Black Maria', 'price': 'Â£52.15'}, {'title': 'Starving Hearts (Triangular Trade Trilogy, #1)', 'price': 'Â£13.99'}, {'title': \"Shakespeare's Sonnets\", 'price': 'Â£20.66'}, {'title': 'Set Me Free', 'price': 'Â£17.46'}, {'title': \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", 'price': 'Â£52.29'}, {'title': 'Rip it Up and Start Again', 'price': 'Â£35.02'}, {'title': 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', 'price': 'Â£57.25'}, {'title': 'Olio', 'price': 'Â£23.88'}, {'title': 'Mesaerion: The Best Science Fiction Stories 1800-1849', 'price': 'Â£37.59'}, {'title': 'Libertarianism for Beginners', 'price': 'Â£51.33'}, {'title': \"It's Only the Himalayas\", 'price': 'Â£45.17'}, {'title': 'In Her Wake', 'price': 'Â£12.84'}, {'title': 'How Music Works', 'price': 'Â£37.32'}, {'title': 'Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More', 'price': 'Â£30.52'}, {'title': 'Chase Me (Paris Nights #2)', 'price': 'Â£25.27'}, {'title': 'Black Dust', 'price': 'Â£34.53'}, {'title': 'Birdsong: A Story in Pictures', 'price': 'Â£54.64'}, {'title': \"America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana\", 'price': 'Â£22.50'}, {'title': 'Aladdin and His Wonderful Lamp', 'price': 'Â£53.13'}, {'title': 'Worlds Elsewhere: Journeys Around Shakespeareâ\\x80\\x99s Globe', 'price': 'Â£40.30'}, {'title': 'Wall and Piece', 'price': 'Â£44.18'}, {'title': 'The Four Agreements: A Practical Guide to Personal Freedom', 'price': 'Â£17.66'}, {'title': 'The Five Love Languages: How to Express Heartfelt Commitment to Your Mate', 'price': 'Â£31.05'}, {'title': 'The Elephant Tree', 'price': 'Â£23.82'}, {'title': 'The Bear and the Piano', 'price': 'Â£36.89'}, {'title': \"Sophie's World\", 'price': 'Â£15.94'}, {'title': 'Penny Maybe', 'price': 'Â£33.29'}, {'title': 'Maude (1883-1993):She Grew Up with the country', 'price': 'Â£18.02'}, {'title': 'In a Dark, Dark Wood', 'price': 'Â£19.63'}, {'title': 'Behind Closed Doors', 'price': 'Â£52.22'}, {'title': \"You can't bury them all: Poems\", 'price': 'Â£33.63'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "all_books = []\n",
    "\n",
    "for page in range(1, 3):  # first 2 pages\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    with open(f'page-{page}.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    books = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    for book in books:\n",
    "        title = book.h3.a['title']\n",
    "        price = book.find('p', class_='price_color').text\n",
    "        all_books.append({'title': title, 'price': price})\n",
    "\n",
    "\n",
    "print(all_books)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be800d3c-6408-4d1b-85ba-6ea16e1a586b",
   "metadata": {},
   "source": [
    "2) Extract the current weather descriptions (like ‘clear’, ‘cloudy’) and temperatures for at least five cities from a public weather site (such as https://www.weather.com or https://wttr.in). Present your data in a tabular format (city, description, temperature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "943124ed-dc17-43fa-a8ad-2c828d42e98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      City Description Temperature\n",
      "0   Mumbai        Haze         89°\n",
      "1     Pune        Haze         78°\n",
      "2   Nashik        Mist         81°\n",
      "3   Nagpur      Cloudy         79°\n",
      "4  Jalgaon         Fog         78°\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# City names and their weather.com location codes\n",
    "cities = {\n",
    "    'Mumbai': 'INXX0096:1:IN',\n",
    "    'Pune': 'INXX0113:1:IN',\n",
    "    'Nashik': 'INXX0121:1:IN',\n",
    "    'Nagpur': 'INXX0114:1:IN',\n",
    "    'Jalgaon': 'INXX0093:1:IN'\n",
    "}\n",
    "\n",
    "base_url = \"https://weather.com/weather/today/l/\"\n",
    "\n",
    "\n",
    "\n",
    "weather_list = []\n",
    "\n",
    "for city, code in cities.items():\n",
    "    url = base_url + code\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract temperature\n",
    "    temp_tag = soup.find('span', attrs={'data-testid': 'TemperatureValue'})\n",
    "    temperature = temp_tag.text if temp_tag else 'N/A'\n",
    "\n",
    "    # Extract description\n",
    "    desc_tag = soup.find('div', attrs={'data-testid': 'wxPhrase'})\n",
    "    description = desc_tag.text if desc_tag else 'N/A'\n",
    "\n",
    "    weather_list.append({\n",
    "        'City': city,\n",
    "        'Description': description,\n",
    "        'Temperature': temperature\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(weather_list)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b023d07-dd1a-4142-bfbe-19451df27367",
   "metadata": {},
   "source": [
    "3) From the “Real Python Fake Jobs” board (https://realpython.github.io/fake-jobs/), gather all job titles, companies, and locations listed on the first three pages. Save the results as a CSV file. Be sure to loop through the pagination and properly parse the HTML for structured data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c3030a-dc7f-4c9a-841c-7cdc0eb5242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 jobs to fake_jobs.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"https://realpython.github.io/fake-jobs\"\n",
    "jobs = []\n",
    "\n",
    "# Loop through pages 1 to 3\n",
    "for page in range(1, 4):\n",
    "    if page == 1:\n",
    "        url = base_url + \"/\"\n",
    "    else:\n",
    "        url = f\"{base_url}/page/{page}/\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Find all job listings\n",
    "    job_cards = soup.find_all(\"div\", class_=\"card-content\")\n",
    "    \n",
    "    for job in job_cards:\n",
    "        title = job.find(\"h2\", class_=\"title\").text.strip()\n",
    "        company = job.find(\"h3\", class_=\"company\").text.strip()\n",
    "        location = job.find(\"p\", class_=\"location\").text.strip()\n",
    "        \n",
    "        jobs.append({\n",
    "            \"Job Title\": title,\n",
    "            \"Company\": company,\n",
    "            \"Location\": location\n",
    "        })\n",
    "\n",
    "# Save results as CSV\n",
    "df = pd.DataFrame(jobs)\n",
    "df.to_csv(\"fake_jobs.csv\", index=False)\n",
    "\n",
    "print(\"Saved\", len(jobs), \"jobs to fake_jobs.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
